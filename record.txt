1.18
尝试的模型：Lasso Regressor
参数：max_z_score=2, max_discrete_score=2.5, discrete_weight=5, auxiliary_data=None, mean_threshold=0.01, cv=ShuffleSplit(n_splits=20,test_size=0.2), alphas=np.arange(0.0001,0.010,0.0002)

测试集成绩：MSE 0.03653，排名28。小汤包期末加油啦～

1.19
尝试的模型：Lasso Regressor
参数：max_z_score=2, max_discrete_score=2.5, discrete_weight=5, auxiliary_data=None, mean_threshold=0.01, zero_equal_na=True, median_thd=0.2, cv=ShuffleSplit(n_splits=30,test_size=0.2), alphas=np.arange(0.0001,0.010,0.0002)

测试集成绩：MSE 0.02142，排名1。下面的朋友们慌不慌><其实我也不知道发生了什么。。

1.20
尝试的模型：Lasso Regressor
参数：max_z_score=3, max_discrete_score=2, discrete_weight=10, auxiliary_data=None, mean_threshold=0.01, zero_equal_na=True, median_thd=0.2, cv=ShuffleSplit(n_splits=30,test_size=0.2), alphas=np.arange(0.0001,0.010,0.0002)

测试集成绩：MSE 0.02259，排名1。万一进决赛了怎么办TT

1.21
尝试的模型：Lasso Regressor
参数：max_z_score=2, max_discrete_score=2.5, discrete_weight=5, auxiliary_data=None, mean_threshold=0.01, zero_equal_na=True, median_thd=0.2, fillna(0), cv=ShuffleSplit(n_splits=30,test_size=0.2), alphas=np.arange(0.001,0.006,0.0002)

测试集成绩：MSE 0.02180，排名1。霸榜的感觉好棒棒o(*≧▽≦)ツ┏━┓

1.22
尝试的模型：Lasso Regressor
参数：max_z_score=2, max_discrete_score=2.5, discrete_weight=5, auxiliary_data=None, mean_threshold=0.01, zero_equal_na=True, median_thd=0.2, alphas=[0.008], y_scaler(with_std=True)

测试集成绩：MSE 0.02693，排名1。下面的朋友你们悠着点o(￣ヘ￣o＃)

1.23
尝试的模型：Lasso Regressor
参数：max_z_score=2, max_discrete_score=5, discrete_weight=1, auxiliary_data=None, mean_threshold=0.01, zero_equal_na=True, median_thd=0.2, cv=ShuffleSplit(n_splits=30,test_size=0.2), np.arange(0.001,0.006,0.0001), method='complex'

测试集成绩：MSE 0.02148，排名1。王小健你小心过拟合A榜啊 ٩(๑´0`๑)۶

1.24
尝试的模型：Lasso Regressor Ensemble
参数1：max_z_score=2, max_discrete_score=5, discrete_weight=1, auxiliary_data=None, mean_threshold=0.01, zero_equal_na=True, median_thd=0.2, cv=ShuffleSplit(n_splits=30,test_size=0.2), np.arange(0.001,0.006,0.0001), method='complex'
参数2：max_z_score=2, max_discrete_score=2.5, discrete_weight=5, auxiliary_data=None, mean_threshold=0.01, zero_equal_na=True, median_thd=0.2, cv=ShuffleSplit(n_splits=30,test_size=0.2), alphas=np.arange(0.0001,0.010,0.0002), method='simple', merge_list=[('TOOL (#1)','Chamber ID'),('TOOL (#2)','330X91'),('Tool (#5)', '520X137')]

测试集成绩：MSE 0.02447，排名1。我们怎么突然就认真起来了(?￣△￣)?

1.25
尝试的模型：Baggging Lasso Regressor
参数：max_z_score=2, discrete_max_z_score=5, discrete_weight=1, auxiliary_data=None, mean_threshold=0.01, zero_equal_na=True, median_thd=0.2, method='complex', alpha=0.022, n_estimators=200, max_features=0.7

测试集成绩：MSE 0.01928，排名1。我就是来骗你们过拟合哒(づ￣ 3￣)づ


最终模型提交：
simple模型：max_z_score, max_discrete_score, discrete_weight, auxiliary_data,alpha, merge_list
complex模型: max_z_score, max_discrete_score, discrete_weight, auxiliary_data, alpha
所有模型: mean_threshold, zero_equal_na, median_thd, record_drop, drop_threshold, remove_correlation, ENSEMBLE method
Pay Super Attention to：cv的参数结果与A榜测试集上的最优参数是否符合;任何对于特征选择的操作，即便在多个测试集上得到验证，也要保持警惕;每一个操作都尽量输出结果人工确认。

Question to Ask:
zero_equal_na为True是不是总是比False好？
simple模型和complex模型是否有绝对的好坏？
Bagging模型是否总比单一模型好？
auxiliary_data不传递测试集是否总比传递好？
max_z_score, max_discrete_score, discrete_weight是否有绝对的最优值？

B榜暂时考虑的策略：
第一天提交单一模型，zero_equal_na参数通过多个测试集以及设计实验的方式确定，其他参数通过线下测试集调到尽量优即可，不要求最优。
第一天成绩好的情况下，固定第一天的参数做Bagging。
第一天成绩不好的情况下，调整参数并做Bagging。